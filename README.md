# Trace Analyzer

A powerful Python tool to analyze OpenTelemetry trace files and extract HTTP endpoint performance metrics and Kafka/messaging operations.

Available as both a **CLI tool** and a **Web Application** with REST API.

Perfect for analyzing distributed systems, microservices architectures, event-driven systems, and identifying performance bottlenecks.

## Features

- Efficiently processes large trace files using streaming JSON parsing
- **Analyzes HTTP requests:**
  - Distinguishes between incoming and outgoing HTTP requests
  - Incoming: relative paths (e.g., `/api/users/123`)
  - Outgoing: full URLs (e.g., `http://service.cluster.local/...`)
  - Tracks service-to-service call relationships
- **Analyzes Kafka/messaging operations:**
  - Detects Kafka consumer and producer operations
  - Tracks message processing spans
  - Extracts message IDs, service IDs, and operation details
- Extracts and groups endpoints by service name
- Detects and normalizes URL parameters (UUIDs, numeric IDs, encoded strings)
- **Tracks timing information** - calculates total time spent per endpoint/operation
- Tracks each unique endpoint-parameter combination per service
- Generates comprehensive reports with:
  - Summary statistics across all services (requests + time)
  - Section 1: Incoming HTTP requests by service
  - Section 2: Service-to-service HTTP calls (caller ‚Üí callee)
  - Section 3: Kafka/messaging operations by service
  - Table of contents with service links
  - Each table includes: Operation details, Count, **Total Time**
  - **All data sorted by Total Time (descending)** - shows slowest operations first

## Quick Start

See [QUICKSTART.md](QUICKSTART.md) for a quick 3-step guide to get started!

## About

This tool analyzes OpenTelemetry trace files exported from observability platforms like Grafana, Jaeger, or similar systems. It provides insights into:
- Service-level performance metrics
- HTTP endpoint call frequencies and latencies
- Service-to-service communication patterns
- Kafka/messaging operation patterns and performance
- Performance bottlenecks in both HTTP and messaging layers

## Project Structure

```
Trace_Analyser/
‚îú‚îÄ‚îÄ analyze_trace.py      # CLI script for trace analysis
‚îú‚îÄ‚îÄ app.py                # Flask web application
‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îú‚îÄ‚îÄ templates/            # HTML templates
‚îÇ   ‚îú‚îÄ‚îÄ index.html       # Upload page
‚îÇ   ‚îî‚îÄ‚îÄ results.html     # Results page
‚îú‚îÄ‚îÄ static/              # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ style.css        # CSS styling
‚îú‚îÄ‚îÄ README.md            # Full documentation
‚îú‚îÄ‚îÄ QUICKSTART.md        # Quick start guide
‚îî‚îÄ‚îÄ .gitignore          # Git ignore rules
```

## Installation

1. **Clone or download this repository**

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

## Docker Deployment

### Using Docker

1. **Build the image:**
```bash
docker build -t trace-analyzer .
```

2. **Run the container:**
```bash
docker run -p 5000:5000 trace-analyzer
```

Then open `http://localhost:5000` in your browser.

### Using Docker Compose

1. **Start the service:**
```bash
docker-compose up --build
```

2. **Access the application:**
Open `http://localhost:5000` in your browser.

3. **Stop the service:**
```bash
docker-compose down
```

## Usage

### Option 1: Web Application (Recommended)

1. **Start the web server:**
```bash
python app.py
```

2. **Open your browser:**
```
http://localhost:5000
```

3. **Upload and analyze:**
   - Drag and drop or select your trace JSON file
   - Click "Analyze Trace File"
   - View interactive results with sortable tables

**Features:**
- üìä Interactive HTML interface
- üìà Visual statistics dashboard
- üîç **Sortable tables** - Click column headers to sort (Count, Total Time)
- üì± Responsive design for mobile
- üöÄ REST API for programmatic access

### Option 2: Command Line Interface

**Basic usage (strips query parameters by default):**
```bash
python analyze_trace.py trace_file.json
```

**Custom output file:**
```bash
python analyze_trace.py trace_file.json -o my_report.md
```

**Keep query parameters (not recommended):**
```bash
python analyze_trace.py trace_file.json --keep-query-params
```

**View all options:**
```bash
python analyze_trace.py --help
```

**Output:** Generates a markdown file with analysis results.

### Option 3: REST API

**Analyze a trace file via API (strips query parameters by default):**
```bash
curl -X POST -F "file=@trace_file.json" \
  http://localhost:5000/api/analyze
```

**Keep query parameters:**
```bash
curl -X POST \
  -F "file=@trace_file.json" \
  -F "strip_query_params=false" \
  http://localhost:5000/api/analyze
```

**Response:** JSON with complete analysis results including services, endpoints, and timing data.

## Output

The script generates a markdown file (`trace_analysis.md` by default) with two main sections:

### 1. Incoming Requests by Service
- Shows **only incoming HTTP requests** that each service receives (relative paths)
- Excludes outgoing calls to other services
- Separate table for each service with their received endpoints
- Includes count and **total time spent** per endpoint
- **Sorted by total time (descending)** - slowest endpoints appear first

### 2. Service-to-Service Calls (Outgoing)
- Shows **outgoing HTTP calls** from one service to another
- Extracted from full URLs (e.g., `http://data-service.data-service.svc...`)
- Grouped by caller ‚Üí callee service pairs
- Each pair shows which endpoints are called with counts and total time
- **Sorted by total time (descending)** per service pair

The report also includes:
- Summary statistics at the top (requests and time)
- Table of contents with links to each service section (includes time per service)
- Console output with service-level statistics and **top 10 slowest endpoints**

### Example Output

```markdown
# Trace Endpoint Analysis Report

**Total Incoming Requests:** 150  
**Total Time (Incoming):** 45.30 s  
**Unique Services:** 2  
**Unique Normalized Endpoints:** 5  
**Unique Endpoint-Parameter Combinations:** 8  

---

## Table of Contents - Incoming Requests by Service

- [api-service](#api-service) (100 requests, 30.50 s)
- [user-service](#user-service) (50 requests, 14.80 s)

---

# Incoming Requests by Service

*This section shows endpoints that each service receives (incoming HTTP requests).*  
*Tables are sorted by Total Time (descending).*

## api-service

**Service Requests:** 100  
**Total Time:** 30.50 s  
**Unique Combinations:** 5  

| Normalized Endpoint | Parameter Value | Count | Total Time |
|---------------------|-----------------|-------|------------|
| /api/posts/{id} | 42 | 45 | 18.50 s |
| /api/posts/{id} | 99 | 30 | 8.20 s |
| /api/users/{uuid} | [no-params] | 25 | 3.80 s |

## user-service

**Service Requests:** 50  
**Total Time:** 14.80 s  
**Unique Combinations:** 3  

| Normalized Endpoint | Parameter Value | Count | Total Time |
|---------------------|-----------------|-------|------------|
| /v1/users/{encoded_id}/profile/{encoded_id} | userProfileView | 30 | 10.20 s |
| /v1/users/{encoded_id}/actions/refresh | [no-params] | 20 | 4.60 s |

---

# Service-to-Service Calls (Outgoing)

*This section shows outgoing HTTP calls from one service to another.*  
*Tables are sorted by Total Time (descending).*

**Total Cross-Service Call Combinations:** 15  
**Total Time (Cross-Service):** 22.40 s  
**Service Pair Relationships:** 2  

## frontend-service ‚Üí backend-service

**Total Calls:** 50  
**Total Time:** 15.60 s  
**Unique Combinations:** 5  

| Normalized Endpoint | Parameter Value | Count | Total Time |
|---------------------|-----------------|-------|------------|
| http://backend-service.backend.svc.cluster.local/v3/{uuid}/data/App__CurrentUser | [no-params] | 25 | 10.20 s |
| http://backend-service.backend.svc.cluster.local/v3/{uuid}/data/{encoded_id} | App__UserSession | 15 | 5.40 s |
```

## Parameter Detection

The analyzer automatically detects and normalizes different types of parameters:

1. **UUIDs**: `xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx` ‚Üí `{uuid}` 
   - Normalized but NOT tracked individually (ignored)
   - Example: `/v1/a21a1909-c664-41be-bfc5-9a3ce0dae52c/api` ‚Üí `/v1/{uuid}/api`

2. **Application identifiers**: `AppName__ResourceName` ‚Üí `{rule_id}`
   - Resource names, class names, and identifiers with double underscores
   - Tracked separately as parameters
   - Example: `/resources/AppName__UserProfile/execute` ‚Üí `/resources/{rule_id}/execute`
   - Example: `/data-pages/AppName__Dashboard?param=value` ‚Üí `/data-pages/{rule_id}?param=value`
   - Tracks: `AppName__UserProfile`, `AppName__Dashboard`, `Service__DataConnector`, etc.

3. **Long encoded strings**: Base64-like strings (30+ chars) ‚Üí `{encoded_id}`
   - Tracked separately as parameters
   - Example: `/cases/RTE6UGVnYVBsYXRmb3JtX1...` ‚Üí `/cases/{encoded_id}`

4. **Numeric IDs**: `/123`, `/456` ‚Üí `/{id}`
   - Tracked separately as parameters
   - Example: `/api/posts/123` ‚Üí `/api/posts/{id}`

**Detection Order:** UUIDs ‚Üí Rule IDs ‚Üí Long encoded ‚Üí Numeric IDs

**Note:** UUID/GUID parameters are ignored and grouped together. All other parameter types are tracked individually.

### Example:
```
/v1/a21a1909-c664-41be-bfc5-9a3ce0dae52c/api/user/123
/v1/a21a1909-c664-41be-bfc5-9a3ce0dae52c/api/user/345
```

Both normalize to `/v1/{uuid}/api/user/{id}`, but only track:
- `/v1/{uuid}/api/user/{id}`, 123, 1
- `/v1/{uuid}/api/user/{id}`, 345, 1

The UUID value `a21a1909-c664-41be-bfc5-9a3ce0dae52c` is ignored.

## Timing Information

The analyzer calculates duration for each span and aggregates it per endpoint:
- Uses `startTimeUnixNano` and `endTimeUnixNano` from OpenTelemetry spans
- Calculates duration in milliseconds
- **Aggregates total time** for each (endpoint, parameter) combination
- Time is formatted for readability:
  - `< 1s`: Shows in milliseconds (e.g., `245.50 ms`)
  - `< 1m`: Shows in seconds (e.g., `12.45 s`)
  - `>= 1m`: Shows in minutes and seconds (e.g., `2m 15.30s`)

**All tables are sorted by Total Time (descending)**, helping you identify performance bottlenecks quickly.

## Incoming vs Outgoing Request Detection

The analyzer distinguishes between incoming and outgoing HTTP requests:

### Incoming Requests (Section 1)
- Detected by **relative paths** (e.g., `/api/users/123`)
- Represents endpoints that the service **receives**
- Tracked per service in the first section

### Outgoing Requests (Section 2)
- Detected by **full URLs** (e.g., `http://service-name.namespace.svc.cluster.local/...`)
- Represents calls the service **makes to other services**
- Target service extracted from the URL hostname
- Tracked as caller ‚Üí callee relationships in the second section

This separation helps you understand:
- What endpoints each service exposes (incoming)
- What external services each service depends on (outgoing)
- Service communication patterns and dependencies
- The flow of requests across your distributed system
- Microservices architecture and inter-service dependencies

## Query Parameter Stripping

By default, the analyzer **strips query parameters** from URLs to group similar endpoints together.

**Example:**
```
Before: /data-pages/Application__ResourceName?param1=abc&param2=xyz
After:  /data-pages/{rule_id}
```

This prevents each unique combination of query parameters from creating separate rows.

**When to keep query parameters:**
- If query parameters represent different endpoints (rare)
- For debugging specific parameter combinations

**How to disable:**
- **CLI**: Add `--keep-query-params` flag
- **Web UI**: Uncheck "Strip query parameters" checkbox
- **API**: Set `strip_query_params=false` in form data

## API Endpoints

### `POST /api/analyze`
Analyze a trace file and return JSON results.

**Request:**
- Method: `POST`
- Content-Type: `multipart/form-data`
- Body: 
  - `file` (required): JSON trace file
  - `strip_query_params` (optional): "true" (default) or "false"

**Response:**
```json
{
  "summary": {
    "total_requests": 150,
    "total_time_ms": 45300,
    "total_time_formatted": "45.30 s",
    "unique_services": 2,
    "unique_endpoints": 5,
    "unique_combinations": 8
  },
  "services": {
    "summary": [...],
    "details": {...}
  },
  "service_calls": [...]
}
```

### `POST /analyze`
Web endpoint that returns HTML results page.

## Configuration

**Web Application Settings (app.py):**
- `MAX_CONTENT_LENGTH`: Maximum file size (default: 500MB)
- `host`: Server host (default: 0.0.0.0)
- `port`: Server port (default: 5000)
- `debug`: Debug mode (default: True)

## Performance

The tool uses streaming JSON parsing (`ijson`) to handle large trace files efficiently without loading the entire file into memory. Both the CLI and web application use the same efficient parsing engine.

